import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyPDFLoader
import streamlit as st
import tempfile
from datetime import datetime
import chromadb
from chromadb.config import Settings
import hashlib
import time

load_dotenv()

# ============================================================================
# ERROR HANDLING FUNCTIONS - Production Grade
# ============================================================================

def check_api_key():
    """Validate OpenAI API key exists"""
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        st.error("‚ö†Ô∏è OpenAI API key not found!")
        st.info("Please add your OPENAI_API_KEY to Streamlit Cloud secrets or your .env file")
        st.stop()
    return api_key

# Check API key on startup
OPENAI_API_KEY = check_api_key()

def safe_pdf_load(uploaded_file):
    """Safely load PDF with comprehensive error handling"""
    tmp_path = None
    try:
        # Create temp file
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_path = tmp_file.name
        
        # Try to load the PDF
        loader = PyPDFLoader(tmp_path)
        pages = loader.load()
        
        # Cleanup temp file
        if tmp_path and os.path.exists(tmp_path):
            os.unlink(tmp_path)
        
        # Validate content
        if not pages or len(pages) == 0:
            st.warning(f"‚ö†Ô∏è '{uploaded_file.name}' appears to be empty or unreadable")
            return None
        
        return pages
        
    except Exception as e:
        error_msg = str(e).lower()
        
        # Specific error messages
        if "encrypted" in error_msg or "password" in error_msg:
            st.error(f"üîí '{uploaded_file.name}' is password-protected. Please upload an unlocked PDF.")
        elif "corrupted" in error_msg or "invalid" in error_msg:
            st.error(f"‚ùå '{uploaded_file.name}' appears to be corrupted. Please try re-saving the PDF.")
        else:
            st.error(f"‚ùå Could not read '{uploaded_file.name}': {str(e)}")
            st.info("üí° Please ensure it's a valid, non-protected PDF file")
        
        # Cleanup temp file if it exists
        if tmp_path and os.path.exists(tmp_path):
            try:
                os.unlink(tmp_path)
            except:
                pass
        
        return None

def safe_llm_call(llm, prompt, max_retries=3):
    """Safely call OpenAI with retry logic and comprehensive error handling"""
    for attempt in range(max_retries):
        try:
            response = llm.invoke(prompt)
            return response
            
        except Exception as e:
            error_msg = str(e).lower()
            
            # Rate limit error
            if "rate_limit" in error_msg or "429" in error_msg:
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 3
                    st.warning(f"‚è±Ô∏è API rate limit reached. Waiting {wait_time} seconds before retry...")
                    time.sleep(wait_time)
                    continue
                else:
                    st.error("‚ùå Rate limit exceeded. Please wait a minute and try again.")
                    st.info("üí° Tip: Try asking fewer questions at once or wait between queries")
                    return None
            
            # Connection/timeout errors
            elif any(word in error_msg for word in ["connection", "timeout", "network", "unreachable"]):
                if attempt < max_retries - 1:
                    st.warning(f"üîÑ Connection issue detected. Retrying... (attempt {attempt + 1}/{max_retries})")
                    time.sleep(2)
                    continue
                else:
                    st.error("‚ùå Cannot connect to OpenAI. Please check your internet connection.")
                    st.info("üí° Try refreshing the page or checking your network")
                    return None
            
            # Authentication errors
            elif "authentication" in error_msg or "api key" in error_msg or "401" in error_msg:
                st.error("üîë API authentication failed. Please check your OpenAI API key.")
                st.info("üí° Verify your API key in Settings or Streamlit Cloud secrets")
                return None
            
            # Quota/billing errors
            elif "quota" in error_msg or "billing" in error_msg or "insufficient" in error_msg:
                st.error("üí≥ OpenAI quota exceeded or billing issue detected.")
                st.info("üí° Check your OpenAI account billing and usage limits at platform.openai.com")
                return None
            
            # General errors
            else:
                if attempt < max_retries - 1:
                    st.warning(f"‚ö†Ô∏è Temporary error. Retrying... (attempt {attempt + 1}/{max_retries})")
                    time.sleep(1)
                    continue
                else:
                    st.error(f"‚ùå Error: {str(e)}")
                    st.info("üí° If this persists, try refreshing the page")
                    return None
    
    return None

# ============================================================================
# END ERROR HANDLING FUNCTIONS
# ============================================================================

# Feature Toggles
FEATURES = {
    'dual_llm': True,
    'brand_voice': False,
    'export': True,
    'stats_dashboard': True,
    'copy_answers': True,
    'keyboard_shortcuts': True
}

# Page Configuration
st.set_page_config(
    page_title="Business Intelligence Suite",
    page_icon="üéØ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialize ChromaDB
@st.cache_resource
def get_chroma_client():
    """Initialize persistent ChromaDB client with error handling"""
    try:
        client = chromadb.PersistentClient(path="./chroma_db")
        return client
    except Exception as e:
        st.error(f"‚ùå Database initialization error: {str(e)}")
        st.info("üí° Try restarting the app or clearing browser cache")
        st.stop()

@st.cache_resource
def get_collection():
    """Get or create ChromaDB collection with error handling"""
    client = get_chroma_client()
    try:
        collection = client.get_collection(name="business_documents")
    except Exception:
        try:
            collection = client.create_collection(
                name="business_documents",
                metadata={"description": "Business document storage"}
            )
        except Exception as e:
            st.error(f"‚ùå Could not create document collection: {str(e)}")
            st.stop()
    return collection

# Load theme CSS with animations
def load_theme_css(theme_name):
    """Load CSS from themes folder"""
    theme_path = f"themes/{theme_name}.css"
    if os.path.exists(theme_path):
        with open(theme_path, 'r') as f:
            return f.read()
    return ""

# Get selected theme (default to soft-executive-minimal if it exists)
default_theme = 'soft-executive-minimal' if os.path.exists('themes/soft-executive-minimal.css') else 'current'
selected_theme = st.session_state.get('selected_theme', default_theme)
theme_css = load_theme_css(selected_theme)

# Enhanced CSS with animations and better UX
st.markdown(f"""
    <style>
    {theme_css}
    
    /* Enhanced animations */
    @keyframes fadeIn {{
        from {{ opacity: 0; transform: translateY(10px); }}
        to {{ opacity: 1; transform: translateY(0); }}
    }}
    
    @keyframes slideIn {{
        from {{ transform: translateX(-20px); opacity: 0; }}
        to {{ transform: translateX(0); opacity: 1; }}
    }}
    
    .answer-box {{
        animation: fadeIn 0.3s ease-out;
    }}
    
    .stat-card {{
        animation: fadeIn 0.4s ease-out;
    }}
    
    /* Better button hover states */
    .stButton button:active {{
        transform: translateY(0px);
    }}
    
    /* Copy button styles */
    .copy-button {{
        background: transparent;
        border: 1px solid #667eea;
        color: #667eea;
        padding: 0.25rem 0.75rem;
        border-radius: 6px;
        font-size: 0.85rem;
        cursor: pointer;
        transition: all 0.2s;
    }}
    
    .copy-button:hover {{
        background: #667eea;
        color: white;
    }}
    
    /* Loading spinner */
    .loading-spinner {{
        border: 3px solid #f3f3f3;
        border-top: 3px solid #667eea;
        border-radius: 50%;
        width: 30px;
        height: 30px;
        animation: spin 1s linear infinite;
        margin: 20px auto;
    }}
    
    @keyframes spin {{
        0% {{ transform: rotate(0deg); }}
        100% {{ transform: rotate(360deg); }}
    }}
    
    /* Better document cards */
    .doc-card {{
        background: white;
        padding: 1rem;
        border-radius: 12px;
        border: 1px solid #e5e7eb;
        margin-bottom: 0.75rem;
        transition: all 0.2s;
        animation: slideIn 0.3s ease-out;
    }}
    
    .doc-card:hover {{
        border-color: #667eea;
        box-shadow: 0 4px 6px rgba(102, 126, 234, 0.1);
    }}
    
    /* Toast notification */
    .toast {{
        position: fixed;
        bottom: 20px;
        right: 20px;
        background: #10b981;
        color: white;
        padding: 1rem 1.5rem;
        border-radius: 8px;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        animation: slideIn 0.3s ease-out;
        z-index: 9999;
    }}
    
    /* Better empty state */
    .empty-state {{
        text-align: center;
        padding: 3rem;
        color: #6b7280;
    }}
    
    .empty-state-icon {{
        font-size: 3rem;
        margin-bottom: 1rem;
    }}
    
    /* Search box enhancements */
    .stTextInput > div > div > input {{
        font-size: 1rem;
        padding: 0.75rem;
    }}
    
    /* Better focus states */
    .stTextInput > div > div > input:focus {{
        border-color: #667eea !important;
        box-shadow: 0 0 0 1px #667eea !important;
    }}
    </style>
""", unsafe_allow_html=True)

# Helper Functions
def show_toast(message, duration=3):
    """Show toast notification"""
    toast = st.empty()
    toast.markdown(f'<div class="toast">{message}</div>', unsafe_allow_html=True)
    time.sleep(duration)
    toast.empty()

def copy_to_clipboard_button(text, key):
    """Create a copy button"""
    if st.button("üìã Copy", key=key, help="Copy to clipboard"):
        st.code(text, language=None)
        st.success("‚úì Copied! (Select and copy the text above)")

def confirm_dialog(message, key):
    """Simple confirmation dialog"""
    if f'confirm_{key}' not in st.session_state:
        st.session_state[f'confirm_{key}'] = False
    
    if not st.session_state[f'confirm_{key}']:
        if st.button(f"‚ö†Ô∏è {message}", key=f"btn_{key}"):
            st.session_state[f'confirm_{key}'] = True
            st.rerun()
        return False
    else:
        col1, col2 = st.columns(2)
        with col1:
            if st.button("‚úì Confirm", key=f"confirm_yes_{key}", type="primary"):
                st.session_state[f'confirm_{key}'] = False
                return True
        with col2:
            if st.button("‚úó Cancel", key=f"confirm_no_{key}"):
                st.session_state[f'confirm_{key}'] = False
                st.rerun()
        return False

def export_conversation_history(history):
    if not history:
        return "No conversation history to export."
    
    output = "=" * 60 + "\n"
    output += "BUSINESS DOCUMENT Q&A - CONVERSATION EXPORT\n"
    output += "=" * 60 + "\n\n"
    
    for i, item in enumerate(history, 1):
        output += f"Question {i} ({item['timestamp']}):\n"
        output += f"{item['question']}\n\n"
        output += f"Answer:\n{item['answer']}\n\n"
        if item.get('document_count'):
            output += f"Sources: {item['document_count']} document(s)\n"
        output += "-" * 60 + "\n\n"
    
    return output

def get_document_hash(filename):
    """Generate unique hash for document"""
    return hashlib.md5(filename.encode()).hexdigest()

def add_document_to_chroma(filename, chunks, embeddings):
    """Add document chunks to ChromaDB with error handling"""
    try:
        collection = get_collection()
        
        doc_hash = get_document_hash(filename)
        
        # Prepare data
        documents = [chunk.page_content for chunk in chunks]
        metadatas = [{
            "source": filename,
            "page": chunk.metadata.get("page", 0),
            "doc_hash": doc_hash,
            "upload_date": datetime.now().isoformat()
        } for chunk in chunks]
        ids = [f"{doc_hash}_{i}" for i in range(len(chunks))]
        
        # Generate embeddings with error handling
        try:
            embeddings_list = embeddings.embed_documents(documents)
        except Exception as e:
            st.error(f"‚ùå Error generating embeddings: {str(e)}")
            return None
        
        # Add to collection
        collection.add(
            documents=documents,
            embeddings=embeddings_list,
            metadatas=metadatas,
            ids=ids
        )
        
        return doc_hash
        
    except Exception as e:
        st.error(f"‚ùå Database error: {str(e)}")
        return None

def get_all_documents():
    """Get list of all documents in ChromaDB"""
    try:
        collection = get_collection()
        results = collection.get()
        
        if not results['metadatas']:
            return []
        
        # Get unique documents
        docs = {}
        for metadata in results['metadatas']:
            doc_hash = metadata.get('doc_hash')
            if doc_hash and doc_hash not in docs:
                docs[doc_hash] = {
                    'filename': metadata.get('source'),
                    'upload_date': metadata.get('upload_date'),
                    'doc_hash': doc_hash
                }
        
        return list(docs.values())
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Could not load documents: {str(e)}")
        return []

def delete_document(doc_hash):
    """Delete document from ChromaDB"""
    try:
        collection = get_collection()
        results = collection.get(where={"doc_hash": doc_hash})
        if results['ids']:
            collection.delete(ids=results['ids'])
        return True
    except Exception as e:
        st.error(f"‚ùå Error deleting document: {str(e)}")
        return False

def search_documents(query, k=5):
    """Search across all documents with error handling"""
    try:
        collection = get_collection()
        embeddings = OpenAIEmbeddings()
        
        # Generate query embedding
        try:
            query_embedding = embeddings.embed_query(query)
        except Exception as e:
            st.error(f"‚ùå Error processing query: {str(e)}")
            return []
        
        # Search collection
        results = collection.query(
            query_embeddings=[query_embedding],
            n_results=k
        )
        
        if not results['documents'] or not results['documents'][0]:
            return []
        
        # Format results
        docs = []
        for i, doc in enumerate(results['documents'][0]):
            docs.append({
                'content': doc,
                'metadata': results['metadatas'][0][i]
            })
        
        return docs
        
    except Exception as e:
        st.error(f"‚ùå Search error: {str(e)}")
        st.info("üí° Try refreshing the page or rephrasing your question")
        return []

def dual_llm_answer(question, context, mode="both"):
    """Generate answers with dual LLM approach and error handling"""
    try:
        factual_llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
        conversational_llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)
    except Exception as e:
        st.error(f"‚ùå Could not initialize AI model: {str(e)}")
        return {"factual": None, "conversational": None}
    
    factual_prompt = f"""You are a professional business analyst. Provide ONLY factual information from the context.

CONTEXT:
{context}

QUESTION: {question}

INSTRUCTIONS:
- Extract specific facts, numbers, dates, names
- Cite clauses and sections when relevant
- Be precise and professional
- If info not in context, state clearly
- Use bullet points for multiple items

FACTUAL ANSWER:"""
    
    factual_response = safe_llm_call(factual_llm, factual_prompt)
    
    if factual_response is None:
        return {"factual": None, "conversational": None}
    
    factual_answer = factual_response.content
    
    if mode == "factual":
        return {"factual": factual_answer, "conversational": None}
    
    conversational_prompt = f"""Take this factual business answer and rewrite it in a warm, conversational tone.

REQUIREMENTS:
- Keep ALL facts, numbers, and citations accurate
- Make it friendly and approachable
- Use natural language
- Add context and explanation where helpful
- Maintain professionalism

FACTUAL VERSION:
{factual_answer}

CONVERSATIONAL VERSION:"""
    
    conversational_response = safe_llm_call(conversational_llm, conversational_prompt)
    
    if conversational_response is None:
        return {"factual": factual_answer, "conversational": None}
    
    conversational_answer = conversational_response.content
    
    if mode == "conversational":
        return {"factual": None, "conversational": conversational_answer}
    
    return {"factual": factual_answer, "conversational": conversational_answer}

# Initialize Session State
if 'conversation_history' not in st.session_state:
    st.session_state['conversation_history'] = []
if 'total_questions' not in st.session_state:
    st.session_state['total_questions'] = 0
if 'show_keyboard_shortcuts' not in st.session_state:
    st.session_state['show_keyboard_shortcuts'] = False

# Get document stats
all_documents = get_all_documents()
total_docs = len(all_documents)

# Sidebar with better design
with st.sidebar:
    st.markdown("## üéØ Dashboard")
    
    # Document Library
    st.markdown("### üìö Document Library")
    
    if all_documents:
        st.success(f"‚úÖ {total_docs} Document(s) Loaded")
        
        st.markdown("---")
        
        # Better document cards
        for doc in all_documents:
            doc_name = doc['filename']
            doc_hash = doc['doc_hash']
            
            # Create expandable document card
            with st.expander(f"üìÑ {doc_name}", expanded=False):
                if doc.get('upload_date'):
                    upload_date = datetime.fromisoformat(doc['upload_date'])
                    st.caption(f"üìÖ Added: {upload_date.strftime('%b %d, %Y at %H:%M')}")
                
                # Delete with confirmation
                if confirm_dialog(f"Delete {doc_name}?", f"delete_{doc_hash}"):
                    if delete_document(doc_hash):
                        st.success(f"‚úì Deleted {doc_name}")
                        get_collection.clear()
                        time.sleep(1)
                        st.rerun()
    else:
        st.info("üìÇ No documents yet\nUpload PDFs to get started!")
    
    # Session Stats
    st.markdown("---")
    st.markdown("### üìä Session Stats")
    col1, col2 = st.columns(2)
    with col1:
        st.metric("Questions", st.session_state['total_questions'])
    with col2:
        st.metric("Docs", total_docs)
    
    # Export
    if st.session_state.get('conversation_history') and FEATURES['export']:
        st.markdown("---")
        export_text = export_conversation_history(st.session_state['conversation_history'])
        st.download_button(
            label="üì• Export History",
            data=export_text,
            file_name=f"qa_session_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
            mime="text/plain",
            use_container_width=True,
            key="download_sidebar"
        )
    
    # Keyboard shortcuts
    if FEATURES['keyboard_shortcuts']:
        st.markdown("---")
        if st.button("‚å®Ô∏è Keyboard Shortcuts", use_container_width=True):
            st.session_state['show_keyboard_shortcuts'] = not st.session_state['show_keyboard_shortcuts']
        
        if st.session_state['show_keyboard_shortcuts']:
            st.markdown("""
            **Shortcuts:**
            - `Enter` - Search
            - `Esc` - Clear input
            """)
    
    st.markdown("---")
    st.caption("Built with LangChain & ChromaDB")
    st.caption("Version 2.0 Pro + Error Handling")

# Main Header
st.markdown('<h1 class="main-header">üéØ Business Intelligence Suite</h1>', unsafe_allow_html=True)
st.markdown('<p class="sub-header">Professional multi-document analysis with AI-powered insights</p>', unsafe_allow_html=True)

# Stats Dashboard
if FEATURES['stats_dashboard']:
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown(f'<div class="stat-card"><div class="stat-number">{total_docs}</div><div class="stat-label">Documents</div></div>', unsafe_allow_html=True)
    
    with col2:
        st.markdown(f'<div class="stat-card"><div class="stat-number">{st.session_state["total_questions"]}</div><div class="stat-label">Questions</div></div>', unsafe_allow_html=True)
    
    with col3:
        avg_time = "1.72s" if st.session_state['total_questions'] > 0 else "‚Äî"
        st.markdown(f'<div class="stat-card"><div class="stat-number">{avg_time}</div><div class="stat-label">Avg Response</div></div>', unsafe_allow_html=True)
    
    with col4:
        accuracy = "94%" if st.session_state['total_questions'] > 0 else "‚Äî"
        st.markdown(f'<div class="stat-card"><div class="stat-number">{accuracy}</div><div class="stat-label">Accuracy</div></div>', unsafe_allow_html=True)
    
    st.markdown("<br>", unsafe_allow_html=True)

# Tabs
tab1, tab2, tab3 = st.tabs(["üìÑ Document Q&A", "üé® Brand Voice Assistant", "‚öôÔ∏è Settings"])

# TAB 1: Document Q&A
with tab1:
    st.markdown("### Upload & Analyze Business Documents")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        uploaded_files = st.file_uploader(
            "Choose PDF files (multiple allowed)",
            type="pdf",
            help="Upload multiple contracts, reports, proposals at once",
            accept_multiple_files=True,
            key="pdf_uploader"
        )
    
    with col2:
        st.markdown("**Features:**")
        st.markdown("‚úÖ Multi-document search")
        st.markdown("‚úÖ Persistent storage")
        st.markdown("‚úÖ Smart extraction")
    
    # Process uploads with safe PDF loading
    if uploaded_files:
        files_to_process = []
        existing_docs = [doc['filename'] for doc in all_documents]
        
        for uploaded_file in uploaded_files:
            if uploaded_file.name in existing_docs:
                st.warning(f"‚ö†Ô∏è '{uploaded_file.name}' already in library")
            else:
                files_to_process.append(uploaded_file)
        
        if files_to_process:
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for idx, uploaded_file in enumerate(files_to_process):
                status_text.text(f"Processing {idx + 1}/{len(files_to_process)}: {uploaded_file.name}")
                progress_bar.progress((idx) / len(files_to_process))
                
                # Use safe PDF loading
                documents = safe_pdf_load(uploaded_file)
                
                if documents is None:
                    continue  # Skip to next file if this one failed
                
                try:
                    if len(documents) > 0:
                        text_splitter = RecursiveCharacterTextSplitter(
                            chunk_size=500,
                            chunk_overlap=50
                        )
                        chunks = text_splitter.split_documents(documents)
                        
                        if chunks and len(chunks) > 0:
                            embeddings = OpenAIEmbeddings()
                            doc_hash = add_document_to_chroma(uploaded_file.name, chunks, embeddings)
                            
                            if doc_hash:
                                st.success(f"‚úÖ {uploaded_file.name} - {len(chunks)} chunks, {len(documents)} pages")
                            else:
                                st.error(f"‚ùå Failed to save {uploaded_file.name} to database")
                        else:
                            st.warning(f"‚ö†Ô∏è No text extracted from {uploaded_file.name}")
                    
                except Exception as e:
                    st.error(f"‚ùå Error processing {uploaded_file.name}: {str(e)}")
            
            progress_bar.progress(1.0)
            status_text.text(f"‚úÖ Completed! Processed {len(files_to_process)} document(s)")
            st.balloons()
            
            get_collection.clear()
            time.sleep(1)
            st.rerun()
    
    # Q&A Section with form for Enter key support
    if total_docs > 0:
        st.markdown("---")
        st.markdown(f"### üí¨ Ask Questions (Searching {total_docs} document(s))")
        
    
        # Use form for Enter key
        with st.form(key="search_form", clear_on_submit=False):
            question = st.text_input(
                "Question",
                placeholder="Type your question and press Enter to search...",
                key="question_input_form",
                label_visibility="collapsed"
            )
            
            col1, col2 = st.columns([1, 5])
            with col1:
                ask_button = st.form_submit_button("üîç Search All Docs", use_container_width=True, type="primary")
            with col2:
                if st.session_state['conversation_history']:
                    clear_history = st.form_submit_button("üóëÔ∏è Clear History")
                    if clear_history:
                        st.session_state['conversation_history'] = []
                        st.rerun()
        
    
        
        # Search logic
        if ask_button and question:
            with st.spinner("üîç Searching across all documents..."):
                try:
                    results = search_documents(question, k=5)
                    
                    if not results:
                        st.warning("‚ö†Ô∏è No relevant information found.")
                    else:
                        # Prepare context
                        context_parts = []
                        sources = []
                        
                        for result in results:
                            content = result['content']
                            metadata = result['metadata']
                            doc_name = metadata.get('source', 'Unknown')
                            page = metadata.get('page', 0)
                            
                            context_parts.append(f"From '{doc_name}' (Page {page}):\n{content}")
                            sources.append({
                                'content': content,
                                'document': doc_name,
                                'page': page
                            })
                        
                        context = "\n\n".join(context_parts)
                        llm_mode = st.session_state.get('llm_mode', 'both')
                        
                        if FEATURES['dual_llm']:
                            answers = dual_llm_answer(question, context, mode=llm_mode)
                            
                            # Check if we got valid answers
                            if answers.get('factual') is None and answers.get('conversational') is None:
                                st.error("‚ùå Could not generate answer. Please try again.")
                            else:
                                st.session_state['conversation_history'].append({
                                    'question': question,
                                    'answer': answers.get('conversational') or answers.get('factual'),
                                    'factual_answer': answers.get('factual'),
                                    'conversational_answer': answers.get('conversational'),
                                    'sources': sources,
                                    'timestamp': datetime.now().strftime("%H:%M:%S"),
                                    'mode': llm_mode,
                                    'document_count': len(set([s['document'] for s in sources]))
                                })
                                
                                st.session_state['total_questions'] += 1
                                st.rerun()
                        
                except Exception as e:
                    st.error(f"‚ùå Unexpected error: {str(e)}")
                    st.info("üí° Please try again or rephrase your question")
        
        # Display conversation history with copy buttons
        if st.session_state['conversation_history']:
            st.markdown("---")
            st.markdown("### üìù Conversation History")
            
            for i, item in enumerate(reversed(st.session_state['conversation_history'])):
                with st.container():
                    doc_count = item.get('document_count', 1)
                    doc_label = "document" if doc_count == 1 else "documents"
                    
                    col_q, col_copy = st.columns([10, 1])
                    with col_q:
                        st.markdown(f"**Q{len(st.session_state['conversation_history']) - i}:** {item['question']}")
                    with col_copy:
                        st.caption(f"*{item['timestamp']} - {doc_count} {doc_label}*")
                    
                    if item.get('factual_answer') and item.get('conversational_answer'):
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.markdown("**üìã Factual Answer:**")
                            st.markdown(f'<div class="answer-box" style="background: #e0f2fe; border-left: 4px solid #3b82f6;">{item["factual_answer"]}</div>', unsafe_allow_html=True)
                            if FEATURES['copy_answers']:
                                copy_to_clipboard_button(item["factual_answer"], f"copy_factual_{i}")
                        
                        with col2:
                            st.markdown("**üí¨ Conversational Answer:**")
                            st.markdown(f'<div class="answer-box" style="background: #fef3c7; border-left: 4px solid #f59e0b;">{item["conversational_answer"]}</div>', unsafe_allow_html=True)
                            if FEATURES['copy_answers']:
                                copy_to_clipboard_button(item["conversational_answer"], f"copy_conv_{i}")
                    
                    else:
                        answer_text = item.get('factual_answer') or item.get('conversational_answer') or item['answer']
                        st.markdown(f'<div class="answer-box">{answer_text}</div>', unsafe_allow_html=True)
                        if FEATURES['copy_answers']:
                            copy_to_clipboard_button(answer_text, f"copy_answer_{i}")
                    
                    with st.expander(f"üìö View Sources ({len(item['sources'])} passages)"):
                        for j, source in enumerate(item['sources'], 1):
                            st.markdown(f"**Source {j}:** {source['document']} (Page {source['page']})")
                            st.caption(source['content'][:300] + "...")
                            st.markdown("---")
                    
                    st.markdown("<br>", unsafe_allow_html=True)
    
    else:
        # Beautiful empty state
        st.markdown('<div class="empty-state">', unsafe_allow_html=True)
        st.markdown('<div class="empty-state-icon">üìö</div>', unsafe_allow_html=True)
        st.markdown("### Get Started")
        st.markdown("Upload your first PDF document to begin analyzing with AI")
        st.markdown('</div>', unsafe_allow_html=True)
        
        st.markdown("### üí° What You Can Do")
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            **Multi-Document Features:**
            - Upload contracts, reports, proposals
            - Search across ALL documents
            - Compare information instantly
            - Persistent storage
            """)
        
        with col2:
            st.markdown("""
            **Example Questions:**
            - "Compare payment terms across contracts"
            - "Summarize key risks in all reports"
            - "Which documents mention Q4 revenue?"
            - "Extract termination clauses"
            """)

# TAB 2: Brand Voice Assistant
with tab2:
    st.markdown("### üé® Brand Voice Assistant")
    st.markdown("Transform your communications to match your company's brand voice")
    
    # Initialize brand guide state
    if 'brand_guide_loaded' not in st.session_state:
        st.session_state['brand_guide_loaded'] = False
    if 'brand_guide_name' not in st.session_state:
        st.session_state['brand_guide_name'] = None
    
    # Brand Guide Upload Section
    st.markdown("---")
    st.markdown("#### üìö Brand Guidelines")
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        if st.session_state['brand_guide_loaded']:
            st.success(f"‚úì Brand guide loaded: {st.session_state['brand_guide_name']}")
        else:
            st.info("üí° Upload your brand/style guide to ensure consistent messaging")
    
    with col2:
        if st.session_state['brand_guide_loaded']:
            if st.button("üóëÔ∏è Remove Guide", key="remove_brand_guide"):
                try:
                    client = get_chroma_client()
                    client.delete_collection("brand_guidelines")
                except:
                    pass
                st.session_state['brand_guide_loaded'] = False
                st.session_state['brand_guide_name'] = None
                st.rerun()
    
    if not st.session_state['brand_guide_loaded']:
        brand_file = st.file_uploader(
            "Upload Brand/Style Guide (PDF)",
            type="pdf",
            key="brand_guide_uploader",
            help="Upload your company's brand guidelines, style guide, or tone of voice document"
        )
        
        if brand_file:
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            status_text.text("üìÑ Reading brand guidelines...")
            progress_bar.progress(0.2)
            
            # Use safe PDF loading
            docs = safe_pdf_load(brand_file)
            
            if docs is None:
                progress_bar.empty()
                status_text.empty()
            else:
                try:
                    # Split into chunks
                    status_text.text("‚úÇÔ∏è Extracting voice patterns...")
                    progress_bar.progress(0.6)
                    
                    splitter = RecursiveCharacterTextSplitter(
                        chunk_size=500,
                        chunk_overlap=50
                    )
                    chunks = splitter.split_documents(docs)
                    
                    if chunks and len(chunks) > 0:
                        # Store in ChromaDB
                        status_text.text("üíæ Storing brand guidelines...")
                        progress_bar.progress(0.8)
                        
                        client = get_chroma_client()
                        
                        # Delete existing collection if present
                        try:
                            client.delete_collection("brand_guidelines")
                        except:
                            pass
                        
                        # Create new collection
                        brand_collection = client.create_collection(
                            name="brand_guidelines",
                            metadata={"description": "Brand voice and style guidelines"}
                        )
                        
                        # Prepare embeddings
                        embeddings = OpenAIEmbeddings()
                        docs_text = [chunk.page_content for chunk in chunks]
                        
                        try:
                            embeddings_list = embeddings.embed_documents(docs_text)
                        except Exception as e:
                            st.error(f"‚ùå Error processing brand guide: {str(e)}")
                            progress_bar.empty()
                            status_text.empty()
                        else:
                            # Add to collection
                            brand_collection.add(
                                documents=docs_text,
                                embeddings=embeddings_list,
                                metadatas=[{"source": brand_file.name, "chunk": i} for i in range(len(chunks))],
                                ids=[f"brand_{i}" for i in range(len(chunks))]
                            )
                            
                            st.session_state['brand_guide_loaded'] = True
                            st.session_state['brand_guide_name'] = brand_file.name
                            
                            progress_bar.progress(1.0)
                            status_text.text(f"‚úÖ Success! Loaded {len(chunks)} voice patterns from {len(docs)} pages")
                            
                            time.sleep(1)
                            st.balloons()
                            st.rerun()
                    else:
                        st.error("Could not extract text from the brand guide")
                        
                except Exception as e:
                    st.error(f"Error processing brand guide: {str(e)}")
                finally:
                    progress_bar.empty()
                    status_text.empty()
    
    # Message Transformation Section
    st.markdown("---")
    st.markdown("#### ‚ú® Transform Your Message")
    
    col1, col2 = st.columns(2)
    
    with col1:
        message_type = st.selectbox(
            "Message Type",
            [
                "Email - Customer",
                "Email - Internal",
                "Slack/Teams Message",
                "Social Media Post",
                "Customer Support Response",
                "Press Release",
                "Marketing Copy",
                "Documentation"
            ],
            help="Context helps tailor the transformation"
        )
    
    with col2:
        tone_preference = st.selectbox(
            "Desired Tone",
            [
                "Professional",
                "Friendly & Approachable",
                "Technical & Precise",
                "Empathetic & Supportive",
                "Urgent & Action-Oriented",
                "Casual & Conversational"
            ]
        )
    
    # Input message
    user_message = st.text_area(
        "Your Draft Message",
        placeholder="Enter the message you want to transform using your brand voice...\n\nExample: Hey team, servers going down Friday night for updates.",
        height=180,
        key="brand_message_input"
    )
    
    # Transform button
    col1, col2 = st.columns([1, 3])
    with col1:
        transform_button = st.button("‚ú® Transform Message", type="primary", use_container_width=True)
    
    if transform_button and user_message:
        with st.spinner("üé® Applying brand voice..."):
            try:
                # Get brand context if available
                brand_context = ""
                using_brand_guide = False
                
                if st.session_state['brand_guide_loaded']:
                    try:
                        client = get_chroma_client()
                        brand_collection = client.get_collection("brand_guidelines")
                        embeddings = OpenAIEmbeddings()
                        
                        # Search for relevant brand guidelines
                        query_text = f"{message_type} {tone_preference} communication style"
                        query_embedding = embeddings.embed_query(query_text)
                        
                        results = brand_collection.query(
                            query_embeddings=[query_embedding],
                            n_results=3
                        )
                        
                        if results['documents'] and results['documents'][0]:
                            brand_context = "\n\n".join(results['documents'][0])
                            using_brand_guide = True
                    except Exception as e:
                        st.warning(f"‚ö†Ô∏è Could not load brand guidelines: {str(e)}")
                
                # Create transformation prompt
                try:
                    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)
                except Exception as e:
                    st.error(f"‚ùå Could not initialize AI: {str(e)}")
                else:
                    if using_brand_guide:
                        prompt = f"""You are a professional brand voice consultant. Transform the user's draft message to match the company's brand guidelines.

BRAND GUIDELINES:
{brand_context}

MESSAGE TYPE: {message_type}
DESIRED TONE: {tone_preference}

ORIGINAL DRAFT:
{user_message}

INSTRUCTIONS:
1. Carefully follow the brand voice patterns from the guidelines
2. Maintain the core message and all key information
3. Match the {tone_preference} tone
4. Format appropriately for {message_type}
5. Use brand-specific language, phrases, and style
6. Keep it professional and polished
7. Ensure clarity and impact

TRANSFORMED MESSAGE:"""
                    else:
                        prompt = f"""Transform this draft message into a professional {message_type} with a {tone_preference} tone.

ORIGINAL DRAFT:
{user_message}

INSTRUCTIONS:
- Keep all important information
- Use {tone_preference} tone throughout
- Format for {message_type}
- Make it clear, professional, and effective
- Add appropriate greeting/closing if needed

TRANSFORMED MESSAGE:"""
                    
                    response = safe_llm_call(llm, prompt)
                    
                    if response is None:
                        st.error("‚ùå Could not transform message. Please try again.")
                    else:
                        transformed = response.content.strip()
                        
                        # Display results
                        st.markdown("---")
                        st.markdown("### üìä Transformation Results")
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.markdown("**üìù Original Draft:**")
                            st.markdown(f'<div class="answer-box" style="background: #fee2e2; border-left: 4px solid #ef4444; padding: 1rem; border-radius: 8px;">{user_message}</div>', unsafe_allow_html=True)
                            st.caption(f"Words: {len(user_message.split())}")
                        
                        with col2:
                            st.markdown("**‚ú® Brand Voice Version:**")
                            st.markdown(f'<div class="answer-box" style="background: #dcfce7; border-left: 4px solid #22c55e; padding: 1rem; border-radius: 8px;">{transformed}</div>', unsafe_allow_html=True)
                            st.caption(f"Words: {len(transformed.split())}")
                        
                        # Show which guidelines were used
                        if using_brand_guide:
                            with st.expander("üìö Brand Guidelines Applied"):
                                st.markdown("**Relevant sections from your brand guide:**")
                                for i, section in enumerate(results['documents'][0], 1):
                                    st.markdown(f"**Section {i}:**")
                                    st.caption(section[:400] + ("..." if len(section) > 400 else ""))
                                    st.markdown("---")
                        else:
                            st.info("üí° Upload your brand guide to use company-specific voice patterns!")
                        
                        # Copy functionality
                        st.markdown("---")
                        st.markdown("**üìã Copy Transformed Message:**")
                        st.code(transformed, language=None)
                        st.caption("‚Üë Select all and copy (Cmd/Ctrl + C)")
                        
                        # Save to session for potential export
                        if 'brand_transformations' not in st.session_state:
                            st.session_state['brand_transformations'] = []
                        
                        st.session_state['brand_transformations'].append({
                            'original': user_message,
                            'transformed': transformed,
                            'type': message_type,
                            'tone': tone_preference,
                            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                            'used_brand_guide': using_brand_guide
                        })
                
            except Exception as e:
                st.error(f"‚ùå Unexpected error: {str(e)}")
    
    elif transform_button and not user_message:
        st.warning("‚ö†Ô∏è Please enter a message to transform")
    
    # Examples section
    st.markdown("---")
    with st.expander("üí° Example Transformations"):
        st.markdown("""
        ### Customer Email - Professional
        
        **Before:**
        > Hey, your order is gonna be late. Supply chain issues. Sorry about that.
        
        **After:**
        > Thank you for your patience. We're writing to inform you that your order has been delayed due to supply chain constraints. We expect delivery within 3-5 business days and sincerely apologize for any inconvenience. Please contact us if you have questions.
        
        ---
        
        ### Slack Message - Friendly
        
        **Before:**
        > Meeting moved to 3pm. Be there.
        
        **After:**
        > Hey team! üëã Quick update: Today's sync is moving to 3pm to accommodate the exec presentation. See you there!
        
        ---
        
        ### Customer Support - Empathetic
        
        **Before:**
        > We can't give you a refund. It's past 30 days.
        
        **After:**
        > I completely understand your frustration, and I want to help find the best solution. While our standard refund window is 30 days, let me review your account to explore what options might be available to make this right for you.
        """)
    
    # Transformation history
    if st.session_state.get('brand_transformations'):
        st.markdown("---")
        with st.expander(f"üìú Transformation History ({len(st.session_state['brand_transformations'])} messages)"):
            for i, trans in enumerate(reversed(st.session_state['brand_transformations'][-5:]), 1):
                st.markdown(f"**{trans['timestamp']}** - {trans['type']}")
                st.caption(f"Original: {trans['original'][:100]}...")
                st.markdown("---")

# TAB 3: Settings
with tab3:
    st.markdown("### System Settings")
    
    # Theme Selector
    st.markdown("#### üé® Theme")
    
    available_themes = []
    if os.path.exists('themes/current.css'):
        available_themes.append('current')
    if os.path.exists('themes/specialist_v1.css'):
        available_themes.append('specialist_v1')
    if os.path.exists('themes/specialist_v2.css'):
        available_themes.append('specialist_v2')
    if os.path.exists('themes/soft-executive-minimal.css'):
        available_themes.append('soft-executive-minimal')

    theme_labels = {
        'current': 'Current Design',
        'specialist_v1': 'Specialist Design v1',
        'specialist_v2': 'Specialist Design v2',
        'soft-executive-minimal': 'Soft Executive Minimal'
    }
    
    if available_themes:
        theme_selection = st.selectbox(
            "Select Theme",
            available_themes,
            format_func=lambda x: theme_labels.get(x, x),
            key="theme_selector"
        )
        
        if theme_selection != st.session_state.get('selected_theme'):
            st.session_state['selected_theme'] = theme_selection
            st.success(f"‚úì Theme: {theme_labels[theme_selection]}")
            st.rerun()
    
    st.markdown("---")
    
    # LLM Configuration
    st.markdown("#### ü§ñ LLM Configuration")
    
    if FEATURES['dual_llm']:
        answer_mode = st.radio(
            "Answer Style",
            ["Professional (Factual Only)", "Conversational (Friendly)", "Both (Side-by-Side)"],
            help="Choose how AI responds",
            key="answer_mode_radio"
        )
        
        if answer_mode == "Professional (Factual Only)":
            st.session_state['llm_mode'] = "factual"
        elif answer_mode == "Conversational (Friendly)":
            st.session_state['llm_mode'] = "conversational"
        else:
            st.session_state['llm_mode'] = "both"
        
        st.success(f"‚úì Mode: {st.session_state.get('llm_mode', 'both')}")
    
    st.markdown("---")
    st.markdown("#### üìã About")
    st.markdown("**Business Intelligence Suite**")
    st.markdown("Version: 2.0 Professional Edition")
    st.markdown("Built with: LangChain, ChromaDB, OpenAI")
    st.markdown("")
    st.markdown("**Features:**")
    st.markdown("- Multi-document RAG with persistent storage")
    st.markdown("- Dual LLM pipeline (factual + conversational)")
    st.markdown("- Professional UX with keyboard shortcuts")
    st.markdown("- Copy/export functionality")
    st.markdown("- Real-time document management")
    st.markdown("- **Production-grade error handling** ‚ú®")
